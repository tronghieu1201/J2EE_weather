"""
XGBoost Weather Forecast Model Training Script
===============================================
Script nÃ y huáº¥n luyá»‡n cÃ¡c model XGBoost Ä‘á»ƒ dá»± Ä‘oÃ¡n thá»i tiáº¿t dá»±a trÃªn dá»¯ liá»‡u lá»‹ch sá»­
tá»« PostgreSQL database (báº£ng weather_history).

Workflow:
1. Káº¿t ná»‘i PostgreSQL vÃ  Ä‘á»c dá»¯ liá»‡u tá»« weather_history
2. Chuáº©n bá»‹ features vÃ  targets
3. Huáº¥n luyá»‡n 3 models: max_temp, min_temp, rain_prob
4. LÆ°u models vÃ o src/main/resources/models/

Cháº¡y: python train_model.py
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
import os
import sys

# Database configuration
DB_CONFIG = {
    'host': 'localhost',
    'database': 'data_weather',
    'user': 'postgres',
    'password': '123456',
    'port': 5432
}

def load_training_data():
    """
    Load dá»¯ liá»‡u thá»±c tá»« PostgreSQL database (báº£ng weather_history).
    """
    print("=" * 60)
    print("BÆ¯á»šC 1: Káº¾T Ná»I DATABASE VÃ€ LOAD Dá»® LIá»†U")
    print("=" * 60)
    
    try:
        import psycopg2
    except ImportError:
        print("ERROR: ChÆ°a cÃ i psycopg2. Cháº¡y: pip install psycopg2-binary")
        sys.exit(1)
    
    try:
        print(f"Káº¿t ná»‘i tá»›i PostgreSQL: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}")
        conn = psycopg2.connect(**DB_CONFIG)
        
        query = """
        SELECT 
            id,
            province,
            latitude,
            longitude,
            record_date,
            temp_max,
            temp_min,
            temp_current,
            humidity,
            wind_speed,
            precipitation,
            precipitation_probability,
            pressure,
            cloud_cover,
            weather_code
        FROM weather_history 
        WHERE temp_max IS NOT NULL 
          AND temp_min IS NOT NULL
        ORDER BY province, record_date
        """
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        print(f"âœ“ ÄÃ£ load {len(df)} báº£n ghi tá»« weather_history")
        print(f"âœ“ Sá»‘ tá»‰nh/thÃ nh cÃ³ dá»¯ liá»‡u: {df['province'].nunique()}")
        
        if len(df) == 0:
            print("\nâš ï¸ Cáº¢NH BÃO: KhÃ´ng cÃ³ dá»¯ liá»‡u trong database!")
            print("   Vui lÃ²ng truy cáº­p http://localhost:8080/admin/data-update")
            print("   vÃ  nháº¥n 'Thu Tháº­p Dá»¯ Liá»‡u' trÆ°á»›c khi cháº¡y script nÃ y.")
            sys.exit(1)
            
        return df
        
    except Exception as e:
        print(f"ERROR: KhÃ´ng thá»ƒ káº¿t ná»‘i database: {e}")
        print("\nÄáº£m báº£o:")
        print("  1. PostgreSQL Ä‘ang cháº¡y")
        print("  2. Database 'weather-j2ee' Ä‘Ã£ tá»“n táº¡i")
        print("  3. ThÃ´ng tin Ä‘Äƒng nháº­p Ä‘Ãºng")
        sys.exit(1)


def prepare_features(df):
    """
    Chuáº©n bá»‹ features vÃ  targets tá»« DataFrame.
    
    Features Ä‘Æ°á»£c táº¡o Ä‘á»ƒ phÃ¹ há»£p vá»›i Java WeatherService:
    - latitude, longitude
    - day_of_year
    - Dá»¯ liá»‡u lá»‹ch sá»­ 3 ngÃ y trÆ°á»›c (temp_max, temp_min, rain_prob)
    """
    print("\n" + "=" * 60)
    print("BÆ¯á»šC 2: CHUáº¨N Bá»Š FEATURES VÃ€ TARGETS")
    print("=" * 60)
    
    # ThÃªm day_of_year tá»« record_date
    df['record_date'] = pd.to_datetime(df['record_date'])
    df['day_of_year'] = df['record_date'].dt.dayofyear
    
    # Sáº¯p xáº¿p theo province vÃ  date
    df = df.sort_values(['province', 'record_date']).reset_index(drop=True)
    
    # Táº¡o features tá»« dá»¯ liá»‡u lá»‹ch sá»­ (shift Ä‘á»ƒ láº¥y ngÃ y trÆ°á»›c)
    training_data = []
    
    for province in df['province'].unique():
        province_df = df[df['province'] == province].copy()
        
        if len(province_df) < 4:  # Cáº§n Ã­t nháº¥t 4 ngÃ y (3 ngÃ y lá»‹ch sá»­ + 1 ngÃ y target)
            continue
        
        # Fill NaN cho precipitation_probability náº¿u khÃ´ng cÃ³ (Archive API khÃ´ng tráº£ vá» trá»±c tiáº¿p)
        if province_df['precipitation_probability'].isna().all():
            # TÃ­nh tá»« precipitation: cÃ³ mÆ°a > 0.1mm = 1, khÃ´ng = 0
            province_df['precipitation_probability'] = (province_df['precipitation'] > 0.1).astype(float)
        else:
            province_df['precipitation_probability'] = province_df['precipitation_probability'].fillna(0)
        
        # Táº¡o lagged features (dá»¯ liá»‡u cá»§a 1, 2, 3 ngÃ y trÆ°á»›c)
        for lag in range(1, 4):
            province_df[f'past_day{lag}_max_temp'] = province_df['temp_max'].shift(lag)
            province_df[f'past_day{lag}_min_temp'] = province_df['temp_min'].shift(lag)
            province_df[f'past_day{lag}_rain_prob'] = province_df['precipitation_probability'].shift(lag)
        
        # Chá»‰ drop NaN trÃªn cÃ¡c cá»™t temp (khÃ´ng drop trÃªn precipitation_probability)
        required_cols = ['past_day1_max_temp', 'past_day1_min_temp', 
                        'past_day2_max_temp', 'past_day2_min_temp',
                        'past_day3_max_temp', 'past_day3_min_temp']
        province_df = province_df.dropna(subset=required_cols)
        
        if len(province_df) > 0:
            training_data.append(province_df)
    
    if len(training_data) == 0:
        print("âš ï¸ KhÃ´ng Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ táº¡o features!")
        print("   Cáº§n Ã­t nháº¥t 4 ngÃ y dá»¯ liá»‡u liÃªn tiáº¿p cho má»—i tá»‰nh.")
        print("   HÃ£y thu tháº­p thÃªm dá»¯ liá»‡u vÃ  cháº¡y láº¡i.")
        sys.exit(1)
    
    final_df = pd.concat(training_data, ignore_index=True)
    
    # Äá»‹nh nghÄ©a features (pháº£i khá»›p vá»›i Java WeatherService)
    feature_columns = [
        'latitude', 'longitude', 'day_of_year',
        'past_day1_max_temp', 'past_day1_min_temp', 'past_day1_rain_prob',
        'past_day2_max_temp', 'past_day2_min_temp', 'past_day2_rain_prob',
        'past_day3_max_temp', 'past_day3_min_temp', 'past_day3_rain_prob'
    ]
    
    X = final_df[feature_columns].fillna(0)  # Fill NaN vá»›i 0
    
    # Targets - dá»± Ä‘oÃ¡n cho ngÃ y hiá»‡n táº¡i
    y_max_temp = final_df['temp_max']
    y_min_temp = final_df['temp_min']
    y_rain_prob = final_df['precipitation_probability'].fillna(0)
    
    print(f"âœ“ Features shape: {X.shape}")
    print(f"âœ“ Feature columns: {feature_columns}")
    print(f"âœ“ Sá»‘ samples Ä‘á»ƒ train: {len(X)}")
    
    return X, y_max_temp, y_min_temp, y_rain_prob


def train_and_save_model(X, y, model_name, output_dir, conn):
    """
    Huáº¥n luyá»‡n XGBoost Regressor, lÆ°u model vÃ  lÆ°u metrics vÃ o database.
    """
    print(f"\n--- Training: {model_name} ---")
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"  Train size: {len(X_train)}, Test size: {len(X_test)}")
    
    # Train model
    model = xgb.XGBRegressor(
        objective='reg:squarederror',
        n_estimators=100,
        learning_rate=0.1,
        max_depth=6,
        random_state=42,
        verbosity=0
    )
    
    model.fit(X_train, y_train)
    
    # Evaluate
    predictions = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, predictions))
    mae = mean_absolute_error(y_test, predictions)
    
    print(f"  âœ“ RMSE: {rmse:.3f}")
    print(f"  âœ“ MAE: {mae:.3f}")
    
    # Save model
    os.makedirs(output_dir, exist_ok=True)
    model_path = os.path.join(output_dir, model_name + ".bin")
    
    booster = model.get_booster()
    booster.save_model(model_path)
    
    print(f"  âœ“ Model saved to: {model_path}")
    
    # LÆ°u metrics vÃ o database
    try:
        save_metrics_to_db(conn, model_name, rmse, mae, len(X_train), len(X_test))
        print(f"  âœ“ Metrics saved to database")
    except Exception as e:
        print(f"  âš  Warning: Could not save metrics to DB: {e}")
    
    return model_path, rmse, mae


def save_metrics_to_db(conn, model_name, rmse, mae, train_samples, test_samples):
    """
    LÆ°u training metrics vÃ o báº£ng model_metrics trong PostgreSQL.
    """
    import json
    from datetime import datetime
    
    cursor = conn.cursor()
    
    # Hyperparameters Ä‘ang sá»­ dá»¥ng
    hyperparams = json.dumps({
        "n_estimators": 100,
        "learning_rate": 0.1,
        "max_depth": 6,
        "objective": "reg:squarederror"
    })
    
    # Táº¡o version tá»± Ä‘á»™ng theo timestamp
    model_version = datetime.now().strftime("v%Y%m%d_%H%M")
    
    sql = """
    INSERT INTO model_metrics 
    (model_name, model_version, rmse, mae, train_samples, test_samples, hyperparameters, trained_at)
    VALUES (%s, %s, %s, %s, %s, %s, %s, NOW())
    """
    
    cursor.execute(sql, (
        model_name, 
        model_version, 
        float(rmse), 
        float(mae), 
        train_samples, 
        test_samples, 
        hyperparams
    ))
    
    conn.commit()
    cursor.close()


def main():
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘       XGBOOST WEATHER FORECAST MODEL TRAINING             â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()
    
    output_dir = "src/main/resources/models/"
    
    # 1. Load data vÃ  láº¥y connection
    import psycopg2
    conn = psycopg2.connect(**DB_CONFIG)
    
    df = load_training_data()
    
    # 2. Prepare features
    X, y_max_temp, y_min_temp, y_rain_prob = prepare_features(df)
    
    # 3. Train models
    print("\n" + "=" * 60)
    print("BÆ¯á»šC 3: HUáº¤N LUYá»†N MODELS")
    print("=" * 60)
    
    results = []
    
    # Max Temperature Model
    path, rmse, mae = train_and_save_model(X, y_max_temp, "daily_model_max_temp", output_dir, conn)
    results.append(("Max Temp", rmse, mae))
    
    # Min Temperature Model
    path, rmse, mae = train_and_save_model(X, y_min_temp, "daily_model_min_temp", output_dir, conn)
    results.append(("Min Temp", rmse, mae))
    
    # Rain Probability Model
    path, rmse, mae = train_and_save_model(X, y_rain_prob, "daily_model_rain_prob", output_dir, conn)
    results.append(("Rain Prob", rmse, mae))
    
    # Close connection
    conn.close()
    
    # Summary
    print("\n" + "=" * 60)
    print("HOÃ€N THÃ€NH!")
    print("=" * 60)
    print("\nKáº¿t quáº£ huáº¥n luyá»‡n:")
    print("-" * 40)
    for name, rmse, mae in results:
        print(f"  {name:15s}: RMSE = {rmse:.3f}, MAE = {mae:.3f}")
    
    print(f"\nModels Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: {output_dir}")
    print("âœ“ Metrics Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o database (table: model_metrics)")
    print("\nğŸ“‹ BÆ¯á»šC TIáº¾P THEO:")
    print("   1. Khá»Ÿi Ä‘á»™ng láº¡i Spring Boot: mvn spring-boot:run")
    print("   2. Truy cáº­p http://localhost:8080 Ä‘á»ƒ xem káº¿t quáº£ dá»± Ä‘oÃ¡n")
    print()


if __name__ == "__main__":
    main()
